{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tweepy\n",
      "  Obtaining dependency information for tweepy from https://files.pythonhosted.org/packages/81/53/ca632ec02085b5c432e98ae1f872a21f2b6bb6c3d022dcf586809cc65cd0/tweepy-4.15.0-py3-none-any.whl.metadata\n",
      "  Downloading tweepy-4.15.0-py3-none-any.whl.metadata (4.1 kB)\n",
      "Collecting oauthlib<4,>=3.2.0 (from tweepy)\n",
      "  Obtaining dependency information for oauthlib<4,>=3.2.0 from https://files.pythonhosted.org/packages/7e/80/cab10959dc1faead58dc8384a781dfbf93cb4d33d50988f7a69f1b7c9bbe/oauthlib-3.2.2-py3-none-any.whl.metadata\n",
      "  Downloading oauthlib-3.2.2-py3-none-any.whl.metadata (7.5 kB)\n",
      "Requirement already satisfied: requests<3,>=2.27.0 in c:\\users\\abhis\\anaconda3\\lib\\site-packages (from tweepy) (2.31.0)\n",
      "Collecting requests-oauthlib<3,>=1.2.0 (from tweepy)\n",
      "  Obtaining dependency information for requests-oauthlib<3,>=1.2.0 from https://files.pythonhosted.org/packages/3b/5d/63d4ae3b9daea098d5d6f5da83984853c1bbacd5dc826764b249fe119d24/requests_oauthlib-2.0.0-py2.py3-none-any.whl.metadata\n",
      "  Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\abhis\\anaconda3\\lib\\site-packages (from requests<3,>=2.27.0->tweepy) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\abhis\\anaconda3\\lib\\site-packages (from requests<3,>=2.27.0->tweepy) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\abhis\\anaconda3\\lib\\site-packages (from requests<3,>=2.27.0->tweepy) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\abhis\\anaconda3\\lib\\site-packages (from requests<3,>=2.27.0->tweepy) (2025.1.31)\n",
      "Downloading tweepy-4.15.0-py3-none-any.whl (99 kB)\n",
      "   ---------------------------------------- 0.0/99.4 kB ? eta -:--:--\n",
      "   ---- ----------------------------------- 10.2/99.4 kB ? eta -:--:--\n",
      "   ---- ----------------------------------- 10.2/99.4 kB ? eta -:--:--\n",
      "   ---- ----------------------------------- 10.2/99.4 kB ? eta -:--:--\n",
      "   ---- ----------------------------------- 10.2/99.4 kB ? eta -:--:--\n",
      "   ------------ --------------------------- 30.7/99.4 kB 108.9 kB/s eta 0:00:01\n",
      "   ------------ --------------------------- 30.7/99.4 kB 108.9 kB/s eta 0:00:01\n",
      "   ------------------------ --------------- 61.4/99.4 kB 181.6 kB/s eta 0:00:01\n",
      "   ------------------------ --------------- 61.4/99.4 kB 181.6 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 99.4/99.4 kB 219.0 kB/s eta 0:00:00\n",
      "Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "   ---------------------------------------- 0.0/151.7 kB ? eta -:--:--\n",
      "   ---------- ----------------------------- 41.0/151.7 kB ? eta -:--:--\n",
      "   ---------- ----------------------------- 41.0/151.7 kB ? eta -:--:--\n",
      "   ----------------------- --------------- 92.2/151.7 kB 871.5 kB/s eta 0:00:01\n",
      "   ----------------------- --------------- 92.2/151.7 kB 871.5 kB/s eta 0:00:01\n",
      "   -------------------------------------- 151.7/151.7 kB 693.4 kB/s eta 0:00:00\n",
      "Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl (24 kB)\n",
      "Installing collected packages: oauthlib, requests-oauthlib, tweepy\n",
      "Successfully installed oauthlib-3.2.2 requests-oauthlib-2.0.0 tweepy-4.15.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tweepy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweets for 'Python':\n",
      "RT @DPR_ALLIEG7: Yugyeom singing Python üò≠ üêç\n",
      "\n",
      "#YUGYEOM #Ïú†Í≤∏ \n",
      "#yugyeom_trusty_NYC\n",
      "#2025TRUSTY_IN_NYC https://t.co/PURLB6O4I8\n",
      "--------------------------------------------------------------------------------\n",
      "„ÅÑ„Çè„ÇÜ„ÇãË®ÄË™ûÈÅ∏ÂÆö„Å†„Å®Go„ÅåÂ§ö„ÅÑ„Çà„Å≠„Å£„Å¶ÊÑü„Åò„Å†„Åë„Å©„Åù„ÅÆ‰∏≠„ÅßRust„ÇíÈÅ∏Êäû„Åó„ÅüÁêÜÁî±„Åå„Çè„Åã„Çä„ÇÑ„Åô„Åã„Å£„Åü\n",
      "‰Ωï„Çà„ÇäÊäÄË°ìÁöÑ„Å™Ëß£ÂÉèÂ∫¶„ÅÆÈ´ò„ÅÑË®ò‰∫ã„Åå„Åã„Åë„ÇãÊäÄË°ìÂ∫ÉÂ†±„ÅÆ‰∫∫„ÅÆ„É¨„Éô„É´ÊÑü„Åå„Åô„Åí„Åà\n",
      "\n",
      "‰∏Ä‰ºë„Å´„Åä„Åë„Çã C#,Python„Åã„ÇâRust„Å∏„ÅÆÁßªË°å„ÅÆÁèæÁä∂„Å®Ë¶ã„Åà„Å¶„Åç„ÅüË™≤È°å\n",
      " https://t.co/AkmLhwiIsh\n",
      "\n",
      " #findy\n",
      "--------------------------------------------------------------------------------\n",
      "RT @bynuchara: ‡πÉ‡∏ô‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î...!! 7 ‡∏õ‡∏µ‡∏ó‡∏µ‡πà‡∏£‡∏≠‡∏Ñ‡∏≠‡∏¢ ‡∏°‡∏≤‡∏Ñ‡πà‡∏∞ ‡πÅ‡∏à‡∏Å‡∏≠‡∏≤‡∏Å‡∏≤‡∏ö‡∏á‡∏õ‡∏•‡∏∏‡∏Å‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏õ‡πá‡∏ô‡∏ô‡∏Å 2 ‡∏≠‡∏±‡∏ô‡∏Ñ‡πà‡∏∞ ‡∏ü‡∏≠‡∏•+‡∏£‡∏µ ‡πÑ‡∏ß‡πâ‡πÑ‡∏î‡πâ‡πÄ‡∏•‡∏¢‡∏Ñ‡πà‡∏∞ ‡∏õ‡∏£‡∏∞‡∏Å‡∏≤‡∏®‡∏ß‡∏±‡∏ô‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÑ‡∏´‡∏£‡πà ‡∏™‡∏∏‡πà‡∏°‡πÅ‡∏à‡∏Å‡πÄ‡∏•‡∏¢üíö\n",
      "#GOT7_N‚Ä¶\n",
      "--------------------------------------------------------------------------------\n",
      "RT @HilmarVeigar: Fantastic write-up on the monumental effort to upgrade our Carbon Engine from Python 2.7 to 3.12. \n",
      "A huge leap forward fo‚Ä¶\n",
      "--------------------------------------------------------------------------------\n",
      "RT @mythssera: Biggest 1st Week Song debuts by a K-pop Group on Spotify in 2025\n",
      "\n",
      "1. HOT ‚Äî 13,263,367 #LESSERAFIM üÜï\n",
      "2. Come Over ‚Äî 5,736,203‚Ä¶\n",
      "--------------------------------------------------------------------------------\n",
      "@so332332 @python_xxt ‰∏ç‰ºöÔºåÂè™Ë¶Å‰∏çÊòØËøá‰∫éËøΩÊ±ÇÊüê‰∫õÁªìËÆ∫ÊàñËÄÖÁ≠îÊ°àÔºå‰∏çËøá‰∫éÊâßÁùÄÊäì‰Ωè‰∫õ‰ªÄ‰πàÔºå‰∏ñÁïåÁöÑ‰∏áÁâ©ÂèòÂåñÊòØÂ∏∏ÊÄÅÔºåÂèØË∞ìÈÅìÂèØÈÅìÈùûÊÅíÈÅìÔºåÈÅìÊ≥ïËá™ÁÑ∂\n",
      "--------------------------------------------------------------------------------\n",
      "RT @bynuchara: ‡πÉ‡∏ô‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î...!! 7 ‡∏õ‡∏µ‡∏ó‡∏µ‡πà‡∏£‡∏≠‡∏Ñ‡∏≠‡∏¢ ‡∏°‡∏≤‡∏Ñ‡πà‡∏∞ ‡πÅ‡∏à‡∏Å‡∏≠‡∏≤‡∏Å‡∏≤‡∏ö‡∏á‡∏õ‡∏•‡∏∏‡∏Å‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏õ‡πá‡∏ô‡∏ô‡∏Å 2 ‡∏≠‡∏±‡∏ô‡∏Ñ‡πà‡∏∞ ‡∏ü‡∏≠‡∏•+‡∏£‡∏µ ‡πÑ‡∏ß‡πâ‡πÑ‡∏î‡πâ‡πÄ‡∏•‡∏¢‡∏Ñ‡πà‡∏∞ ‡∏õ‡∏£‡∏∞‡∏Å‡∏≤‡∏®‡∏ß‡∏±‡∏ô‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÑ‡∏´‡∏£‡πà ‡∏™‡∏∏‡πà‡∏°‡πÅ‡∏à‡∏Å‡πÄ‡∏•‡∏¢üíö\n",
      "#GOT7_N‚Ä¶\n",
      "--------------------------------------------------------------------------------\n",
      "RT @mdancho84: Move over Tableau and PowerBI. \n",
      "\n",
      "There's a new Python library that automates Business Intelligence with AI using Text2SQL.‚Ä¶\n",
      "--------------------------------------------------------------------------------\n",
      "3Ô∏è‚É£ Relaciones lineales: Los modelos de aprendizaje profundo, dise√±ados para capturar relaciones no lineales complejas, pueden no ofrecer ventajas adicionales y ser m√°s costosos computacionalmente.\n",
      "\n",
      "#deeplearning #neuralnetwork #RStats #Python #Code\n",
      "--------------------------------------------------------------------------------\n",
      "2025 Mar 22 (Sat) 16:00:08  \n",
      " Test posted at 1 hour intervals.\n",
      " Conoha-VPS on Linux Debian12.\n",
      " #VScode #Docker #Python #NodeRED \n",
      " #Ë¶≥ÂÖâxIT #Â±±„ÉÑ„Ç§ #3VÂ∞èÊ∞¥ÂäõÁô∫Èõª https://t.co/QWBVz8yxpJ\n",
      "--------------------------------------------------------------------------------\n",
      "Tweets for 'Machine Learning':\n",
      "RT @CarolNdosi: Ratiba za Shule nyingi hazitoi muda wa kutosha kwa mtoto kuwa na extra curricula activities nje ya Shule...ni vema wakajari‚Ä¶\n",
      "--------------------------------------------------------------------------------\n",
      "RT @swapnakpanda: FREE Machine Learning Courses from Stanford:\n",
      "\n",
      "CS221 - Artificial Intelligence\n",
      "CS229 - Machine Learning\n",
      "CS230 - Deep Learn‚Ä¶\n",
      "--------------------------------------------------------------------------------\n",
      "RT @TheSoftLifeNaza: In today‚Äôs rapidly evolving digital landscape, the demand for computing power is surging, driven by advancements in ar‚Ä¶\n",
      "--------------------------------------------------------------------------------\n",
      "RT @CarolNdosi: Ratiba za Shule nyingi hazitoi muda wa kutosha kwa mtoto kuwa na extra curricula activities nje ya Shule...ni vema wakajari‚Ä¶\n",
      "--------------------------------------------------------------------------------\n",
      "RT @tomlikestocode: Machine Learning from Scratchüß†\n",
      "\n",
      "I built an open-source repo with clean Python implementations of ML algorithms.\n",
      "\n",
      "Superv‚Ä¶\n",
      "--------------------------------------------------------------------------------\n",
      "RT @TheSoftLifeNaza: In today‚Äôs rapidly evolving digital landscape, the demand for computing power is surging, driven by advancements in ar‚Ä¶\n",
      "--------------------------------------------------------------------------------\n",
      "Investment in AI and machine learning drives Airbnb's innovation. How do you see these technologies shaping the future? #AIInnovation $AIMASTER\n",
      "--------------------------------------------------------------------------------\n",
      "A Day in the Life of a Machine Learning Engineer (at a *small* startup) https://t.co/slPnUwvs5l Êù•Ëá™ @YouTube\n",
      "--------------------------------------------------------------------------------\n",
      "A Day in the Life of a Machine Learning Engineer (at a *small* startup) https://t.co/54NKYqkKNY via @YouTube\n",
      "--------------------------------------------------------------------------------\n",
      "Open jasa Joki Website Laravel, React, Machine Learning , Project Programming, Praktikum C, C++, C#, Java, Python, SQL, Golang, Full Skripsi, Build CV, Essay, Makalah, Laprak dan Jurnal(Nasional/Internasional) #zonauang #effichrono #Zonajajan #jokikuliah #jokiskripsi #jokimurah https://t.co/kqNH1wVoWq\n",
      "--------------------------------------------------------------------------------\n",
      "Error fetching tweets for 'Data Science': 429 Too Many Requests\n",
      "Too Many Requests\n"
     ]
    }
   ],
   "source": [
    "import tweepy\n",
    "\n",
    "# Replace with your actual credentials from Twitter Developer Portal\n",
    "BEARER_TOKEN = \"AAAAAAAAAAAAAAAAAAAAAGBV0AEAAAAAeXzIXP0NpI3FHy%2F87eLJzeE3F9U%3Dm8DdgsjGcCKWlwzEoT3lpyv54W3pgmfAEAUFpLRuBJHoqWmpeH\"\n",
    "\n",
    "# Initialize the Twitter Client\n",
    "client = tweepy.Client(bearer_token=BEARER_TOKEN)\n",
    "\n",
    "# List of search queries\n",
    "queries = [\"Python\", \"Machine Learning\", \"Data Science\"]\n",
    "\n",
    "# Fetch recent tweets\n",
    "for query in queries:\n",
    "    try:\n",
    "        response = client.search_recent_tweets(query=query, max_results=10)  # Must be between 10-100\n",
    "        if response.data:\n",
    "            print(f\"Tweets for '{query}':\")\n",
    "            for tweet in response.data:\n",
    "                print(tweet.text)\n",
    "                print(\"-\" * 80)\n",
    "        else:\n",
    "            print(f\"No recent tweets found for '{query}'.\")\n",
    "    except tweepy.TweepyException as e:\n",
    "        print(f\"Error fetching tweets for '{query}': {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "import tweepy\n",
    "\n",
    "BEARER_TOKEN = \"AAAAAAAAAAAAAAAAAAAAAGBV0AEAAAAAeXzIXP0NpI3FHy%2F87eLJzeE3F9U%3Dm8DdgsjGcCKWlwzEoT3lpyv54W3pgmfAEAUFpLRuBJHoqWmpeH\"  # Replace with your actual token\n",
    "\n",
    "client = tweepy.Client(bearer_token=BEARER_TOKEN)\n",
    "\n",
    "try:\n",
    "    response = client.get_user(username=\"TwitterDev\")  # Test with a known account\n",
    "    print(response.data)\n",
    "except tweepy.TweepyException as e:\n",
    "    print(f\"Authentication failed: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User not found or private.\n"
     ]
    }
   ],
   "source": [
    "import tweepy\n",
    "\n",
    "BEARER_TOKEN = \"AAAAAAAAAAAAAAAAAAAAAGBV0AEAAAAAeXzIXP0NpI3FHy%2F87eLJzeE3F9U%3Dm8DdgsjGcCKWlwzEoT3lpyv54W3pgmfAEAUFpLRuBJHoqWmpeH\"  # Ensure it's correct\n",
    "\n",
    "client = tweepy.Client(bearer_token=BEARER_TOKEN)\n",
    "\n",
    "try:\n",
    "    user = client.get_user(username=\"TwitterDev\", user_fields=[\"id\", \"name\", \"username\"])\n",
    "    if user.data:\n",
    "        print(user.data)\n",
    "    else:\n",
    "        print(\"User not found or private.\")\n",
    "except tweepy.TweepyException as e:\n",
    "    print(f\"Authentication failed: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweet ID: 1903344966396715187\n",
      "Author ID: 116378023\n",
      "Created At: 2025-03-22 07:16:17+00:00\n",
      "Tweet: ‰ªäÊó•„ÅØPython„Åß„Ç≠„É£„ÉÉ„ÉÅ„Ç≤„Éº„É†„Çí‰Ωú„Å£„Å¶„Åø„Åæ„Åó„ÅüÔºÅ\n",
      "„ÄåÂâµ„Çã„Äç„ÅåÊïô„Åà„Å¶„Åè„Çå„Çã‰∫∫Áîü„ÅÆË±ä„Åã„ÅïÔΩúÂåóÊñó„ÅÆ„Åë„Çì„Å°„ÇÉ„Çì #note https://t.co/eOkX1P9SK5 https://t.co/myISaji03V\n",
      "--------------------------------------------------------------------------------\n",
      "Tweet ID: 1903344941666836692\n",
      "Author ID: 169904826\n",
      "Created At: 2025-03-22 07:16:11+00:00\n",
      "Tweet: @elricmann If you think that tech merit plays the fundamental role in popularity you're in for some serious disappointment.\n",
      "\n",
      "It's not totally irrelevant of course, but the lion share for popularity is just random. What is popular becomes more popular.\n",
      "\n",
      "Python simply \"won the lottery\" of AI.\n",
      "--------------------------------------------------------------------------------\n",
      "Tweet ID: 1903344859101925561\n",
      "Author ID: 1681990614840233987\n",
      "Created At: 2025-03-22 07:15:51+00:00\n",
      "Tweet: @gina_millionz It's kinda using computer code (python)\n",
      "\n",
      "To make animation \n",
      "\n",
      "And ston fi is a Dex on Ton Blockchain\n",
      "--------------------------------------------------------------------------------\n",
      "Tweet ID: 1903344791363965120\n",
      "Author ID: 1896823525060550656\n",
      "Created At: 2025-03-22 07:15:35+00:00\n",
      "Tweet: üöÄ Bootcamps are a fast track to data science!\n",
      "üëâComprehensive curriculum (Python, ML)\n",
      "üëâHands-on projects, mentorship &amp; career guidance\n",
      "Top picks: Springboard, Flatiron, General Assembly, Refonte Learning.\n",
      "Start here: https://t.co/8jVPSQMtiz\n",
      "#DataScience #Bootcamps #CareerSwitch https://t.co/hBN5cXighr\n",
      "--------------------------------------------------------------------------------\n",
      "Tweet ID: 1903344657364353114\n",
      "Author ID: 1900654473196040192\n",
      "Created At: 2025-03-22 07:15:03+00:00\n",
      "Tweet: üî• Big News!\n",
      "\n",
      "#ElonMusk officially introduces the X Token.üéâ\n",
      "\n",
      "‚ûû ùóΩùó∂ùóª ùóΩùóºùòÄùòÅ https://t.co/Xam9T52TZw\n",
      "\n",
      " @f_montero_89ins\n",
      "--------------------------------------------------------------------------------\n",
      "Tweet ID: 1903344651643347099\n",
      "Author ID: 1891044786225795072\n",
      "Created At: 2025-03-22 07:15:02+00:00\n",
      "Tweet: fenala≈üƒ±p halletsek BOMBANƒ±N kurtaracaƒüƒ±nƒ± PYTHON ‚òé #test ‚úà ‚ò∫Ô∏è kilometre https://t.co/pzH45N4q3w\n",
      "--------------------------------------------------------------------------------\n",
      "Tweet ID: 1903344488115847204\n",
      "Author ID: 352410832\n",
      "Created At: 2025-03-22 07:14:23+00:00\n",
      "Tweet: @Danjsalt Yep the liberal elite are the black knight in Monty Pythonü§® https://t.co/QT8VpaV66d\n",
      "--------------------------------------------------------------------------------\n",
      "Tweet ID: 1903344476669563002\n",
      "Author ID: 1877683550709014528\n",
      "Created At: 2025-03-22 07:14:20+00:00\n",
      "Tweet: @webdesignerng @CharlesChu4891 Na em go swallow python\n",
      "--------------------------------------------------------------------------------\n",
      "Tweet ID: 1903344109881860468\n",
      "Author ID: 1864218041942417408\n",
      "Created At: 2025-03-22 07:12:52+00:00\n",
      "Tweet: @Python_Dv I just learned about this - the .split() function splits a variable into a list. Each whitespace, tab, or new line is excluded by the split function, and each word is saved to a different index. [::-1] reverses the order of that list, so I believe the answer is A.\n",
      "--------------------------------------------------------------------------------\n",
      "Tweet ID: 1903344048150286494\n",
      "Author ID: 1352577733256228865\n",
      "Created At: 2025-03-22 07:12:38+00:00\n",
      "Tweet: ‡∏û‡∏ô‡∏à‡∏∞‡πÑ‡∏î‡πâ‡∏î‡∏π‡∏≠‡πâ‡∏ß‡∏•‡πÄ‡∏ï‡πâ‡∏ô python ‡πÅ‡∏¢‡πâ‡∏ß‡∏≠‡∏∞ ‡∏ä‡πâ‡∏≤‡∏ô‡∏à‡∏∞‡πÄ‡∏™‡∏µ‡∏¢‡∏Å‡πà‡∏≠‡∏ô‡∏°‡∏±‡πâ‡∏¢ ‡∏ó‡∏∏‡∏Å‡∏ß‡∏±‡∏ô‡∏ô‡∏µ‡πâ‡πÄ‡∏û‡∏•‡∏á‡∏£‡∏±‡∏ô‡∏°‡∏≤‡∏Ñ‡∏∑‡∏≠‡πÄ‡∏Ç‡∏¥‡∏ô‡∏à‡∏ô‡∏´‡∏ô‡πâ‡∏≤‡πÄ‡∏ö‡∏µ‡πâ‡∏¢‡∏ß‡∏à‡∏≤‡∏Å‡∏Ñ‡∏ô‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡πÄ‡∏Ñ‡∏¢‡∏ü‡∏±‡∏á‡πÄ‡∏û‡∏•‡∏á‡∏ô‡∏µ‡πâ‡πÄ‡∏•‡∏¢‡∏ó‡∏∏‡∏Å‡∏ß‡∏±‡∏ô‡∏ô‡∏µ‡πâ‡∏Ñ‡∏∑‡∏≠‡∏ü‡∏±‡∏á‡∏ó‡∏∏‡∏Å‡∏ß‡∏±‡∏ô ‡∏Ñ‡∏¥‡∏î‡∏ñ‡∏∂‡∏á‡∏≠‡πâ‡∏ß‡∏•‡∏•‡∏•‡∏•\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import tweepy\n",
    "\n",
    "# Replace with your actual Bearer Token\n",
    "BEARER_TOKEN = \"AAAAAAAAAAAAAAAAAAAAAGBV0AEAAAAAFXB6uYQbt%2BGDqcRc3gXhf1F1ivQ%3DZ4X3OBJ2SO775CC6d5TUmbcal9f6TW5Hu9sGYEKznbI8MXFvf3\"\n",
    "\n",
    "# Initialize Tweepy client\n",
    "client = tweepy.Client(bearer_token=BEARER_TOKEN)\n",
    "\n",
    "# Define the search query\n",
    "query = \"Python -is:retweet\"  # Excludes retweets\n",
    "\n",
    "try:\n",
    "    # Fetch recent tweets\n",
    "    response = client.search_recent_tweets(query=query, max_results=10, tweet_fields=[\"created_at\", \"author_id\"])\n",
    "\n",
    "    # Check if tweets are retrieved\n",
    "    if response.data:\n",
    "        for tweet in response.data:\n",
    "            print(f\"Tweet ID: {tweet.id}\")\n",
    "            print(f\"Author ID: {tweet.author_id}\")\n",
    "            print(f\"Created At: {tweet.created_at}\")\n",
    "            print(f\"Tweet: {tweet.text}\")\n",
    "            print(\"-\" * 80)\n",
    "    else:\n",
    "        print(\"No tweets found for the given query.\")\n",
    "except tweepy.TweepyException as e:\n",
    "    print(f\"Error: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Waiting for 15 minutes...\n"
     ]
    }
   ],
   "source": [
    "import tweepy\n",
    "import pandas as pd\n",
    "import json\n",
    "import time\n",
    "\n",
    "# Replace with your actual credentials\n",
    "BEARER_TOKEN = \"AAAAAAAAAAAAAAAAAAAAAGBV0AEAAAAAFXB6uYQbt%2BGDqcRc3gXhf1F1ivQ%3DZ4X3OBJ2SO775CC6d5TUmbcal9f6TW5Hu9sGYEKznbI8MXFvf3\"\n",
    "\n",
    "client = tweepy.Client(bearer_token=BEARER_TOKEN)\n",
    "\n",
    "query = \"Python -is:retweet lang:en\"\n",
    "\n",
    "def fetch_tweets():\n",
    "    while True:\n",
    "        try:\n",
    "            tweets = client.search_recent_tweets(\n",
    "                query=query, tweet_fields=[\"id\", \"text\", \"created_at\", \"author_id\"], max_results=5\n",
    "            )\n",
    "            return tweets\n",
    "        except tweepy.TooManyRequests:\n",
    "            print(\"Rate limit exceeded. Waiting for 15 minutes...\")\n",
    "            time.sleep(900)  # Wait for 15 minutes before retrying\n",
    "\n",
    "tweets = fetch_tweets()\n",
    "\n",
    "if tweets and tweets.data:\n",
    "    tweet_list = [{\n",
    "        \"Tweet ID\": tweet.id,\n",
    "        \"Author ID\": tweet.author_id,\n",
    "        \"Created At\": tweet.created_at.strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "        \"Tweet\": tweet.text\n",
    "    } for tweet in tweets.data]\n",
    "\n",
    "    df = pd.DataFrame(tweet_list)\n",
    "    df.to_csv(\"tweets.csv\", index=False, encoding=\"utf-8\")\n",
    "\n",
    "    with open(\"tweets.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(tweet_list, f, indent=4)\n",
    "\n",
    "    print(\"Tweets saved successfully!\")\n",
    "else:\n",
    "    print(\"No tweets found.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
