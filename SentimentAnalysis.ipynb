{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tweepy\n",
      "  Obtaining dependency information for tweepy from https://files.pythonhosted.org/packages/81/53/ca632ec02085b5c432e98ae1f872a21f2b6bb6c3d022dcf586809cc65cd0/tweepy-4.15.0-py3-none-any.whl.metadata\n",
      "  Downloading tweepy-4.15.0-py3-none-any.whl.metadata (4.1 kB)\n",
      "Collecting oauthlib<4,>=3.2.0 (from tweepy)\n",
      "  Obtaining dependency information for oauthlib<4,>=3.2.0 from https://files.pythonhosted.org/packages/7e/80/cab10959dc1faead58dc8384a781dfbf93cb4d33d50988f7a69f1b7c9bbe/oauthlib-3.2.2-py3-none-any.whl.metadata\n",
      "  Downloading oauthlib-3.2.2-py3-none-any.whl.metadata (7.5 kB)\n",
      "Requirement already satisfied: requests<3,>=2.27.0 in c:\\users\\abhis\\anaconda3\\lib\\site-packages (from tweepy) (2.31.0)\n",
      "Collecting requests-oauthlib<3,>=1.2.0 (from tweepy)\n",
      "  Obtaining dependency information for requests-oauthlib<3,>=1.2.0 from https://files.pythonhosted.org/packages/3b/5d/63d4ae3b9daea098d5d6f5da83984853c1bbacd5dc826764b249fe119d24/requests_oauthlib-2.0.0-py2.py3-none-any.whl.metadata\n",
      "  Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\abhis\\anaconda3\\lib\\site-packages (from requests<3,>=2.27.0->tweepy) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\abhis\\anaconda3\\lib\\site-packages (from requests<3,>=2.27.0->tweepy) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\abhis\\anaconda3\\lib\\site-packages (from requests<3,>=2.27.0->tweepy) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\abhis\\anaconda3\\lib\\site-packages (from requests<3,>=2.27.0->tweepy) (2025.1.31)\n",
      "Downloading tweepy-4.15.0-py3-none-any.whl (99 kB)\n",
      "   ---------------------------------------- 0.0/99.4 kB ? eta -:--:--\n",
      "   ---- ----------------------------------- 10.2/99.4 kB ? eta -:--:--\n",
      "   ---- ----------------------------------- 10.2/99.4 kB ? eta -:--:--\n",
      "   ---- ----------------------------------- 10.2/99.4 kB ? eta -:--:--\n",
      "   ---- ----------------------------------- 10.2/99.4 kB ? eta -:--:--\n",
      "   ------------ --------------------------- 30.7/99.4 kB 108.9 kB/s eta 0:00:01\n",
      "   ------------ --------------------------- 30.7/99.4 kB 108.9 kB/s eta 0:00:01\n",
      "   ------------------------ --------------- 61.4/99.4 kB 181.6 kB/s eta 0:00:01\n",
      "   ------------------------ --------------- 61.4/99.4 kB 181.6 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 99.4/99.4 kB 219.0 kB/s eta 0:00:00\n",
      "Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "   ---------------------------------------- 0.0/151.7 kB ? eta -:--:--\n",
      "   ---------- ----------------------------- 41.0/151.7 kB ? eta -:--:--\n",
      "   ---------- ----------------------------- 41.0/151.7 kB ? eta -:--:--\n",
      "   ----------------------- --------------- 92.2/151.7 kB 871.5 kB/s eta 0:00:01\n",
      "   ----------------------- --------------- 92.2/151.7 kB 871.5 kB/s eta 0:00:01\n",
      "   -------------------------------------- 151.7/151.7 kB 693.4 kB/s eta 0:00:00\n",
      "Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl (24 kB)\n",
      "Installing collected packages: oauthlib, requests-oauthlib, tweepy\n",
      "Successfully installed oauthlib-3.2.2 requests-oauthlib-2.0.0 tweepy-4.15.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tweepy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweets for 'Python':\n",
      "RT @DPR_ALLIEG7: Yugyeom singing Python 😭 🐍\n",
      "\n",
      "#YUGYEOM #유겸 \n",
      "#yugyeom_trusty_NYC\n",
      "#2025TRUSTY_IN_NYC https://t.co/PURLB6O4I8\n",
      "--------------------------------------------------------------------------------\n",
      "いわゆる言語選定だとGoが多いよねって感じだけどその中でRustを選択した理由がわかりやすかった\n",
      "何より技術的な解像度の高い記事がかける技術広報の人のレベル感がすげえ\n",
      "\n",
      "一休における C#,PythonからRustへの移行の現状と見えてきた課題\n",
      " https://t.co/AkmLhwiIsh\n",
      "\n",
      " #findy\n",
      "--------------------------------------------------------------------------------\n",
      "RT @bynuchara: ในที่สุด...!! 7 ปีที่รอคอย มาค่ะ แจกอากาบงปลุกความเป็นนก 2 อันค่ะ ฟอล+รี ไว้ได้เลยค่ะ ประกาศวันเมื่อไหร่ สุ่มแจกเลย💚\n",
      "#GOT7_N…\n",
      "--------------------------------------------------------------------------------\n",
      "RT @HilmarVeigar: Fantastic write-up on the monumental effort to upgrade our Carbon Engine from Python 2.7 to 3.12. \n",
      "A huge leap forward fo…\n",
      "--------------------------------------------------------------------------------\n",
      "RT @mythssera: Biggest 1st Week Song debuts by a K-pop Group on Spotify in 2025\n",
      "\n",
      "1. HOT — 13,263,367 #LESSERAFIM 🆕\n",
      "2. Come Over — 5,736,203…\n",
      "--------------------------------------------------------------------------------\n",
      "@so332332 @python_xxt 不会，只要不是过于追求某些结论或者答案，不过于执着抓住些什么，世界的万物变化是常态，可谓道可道非恒道，道法自然\n",
      "--------------------------------------------------------------------------------\n",
      "RT @bynuchara: ในที่สุด...!! 7 ปีที่รอคอย มาค่ะ แจกอากาบงปลุกความเป็นนก 2 อันค่ะ ฟอล+รี ไว้ได้เลยค่ะ ประกาศวันเมื่อไหร่ สุ่มแจกเลย💚\n",
      "#GOT7_N…\n",
      "--------------------------------------------------------------------------------\n",
      "RT @mdancho84: Move over Tableau and PowerBI. \n",
      "\n",
      "There's a new Python library that automates Business Intelligence with AI using Text2SQL.…\n",
      "--------------------------------------------------------------------------------\n",
      "3️⃣ Relaciones lineales: Los modelos de aprendizaje profundo, diseñados para capturar relaciones no lineales complejas, pueden no ofrecer ventajas adicionales y ser más costosos computacionalmente.\n",
      "\n",
      "#deeplearning #neuralnetwork #RStats #Python #Code\n",
      "--------------------------------------------------------------------------------\n",
      "2025 Mar 22 (Sat) 16:00:08  \n",
      " Test posted at 1 hour intervals.\n",
      " Conoha-VPS on Linux Debian12.\n",
      " #VScode #Docker #Python #NodeRED \n",
      " #観光xIT #山ツイ #3V小水力発電 https://t.co/QWBVz8yxpJ\n",
      "--------------------------------------------------------------------------------\n",
      "Tweets for 'Machine Learning':\n",
      "RT @CarolNdosi: Ratiba za Shule nyingi hazitoi muda wa kutosha kwa mtoto kuwa na extra curricula activities nje ya Shule...ni vema wakajari…\n",
      "--------------------------------------------------------------------------------\n",
      "RT @swapnakpanda: FREE Machine Learning Courses from Stanford:\n",
      "\n",
      "CS221 - Artificial Intelligence\n",
      "CS229 - Machine Learning\n",
      "CS230 - Deep Learn…\n",
      "--------------------------------------------------------------------------------\n",
      "RT @TheSoftLifeNaza: In today’s rapidly evolving digital landscape, the demand for computing power is surging, driven by advancements in ar…\n",
      "--------------------------------------------------------------------------------\n",
      "RT @CarolNdosi: Ratiba za Shule nyingi hazitoi muda wa kutosha kwa mtoto kuwa na extra curricula activities nje ya Shule...ni vema wakajari…\n",
      "--------------------------------------------------------------------------------\n",
      "RT @tomlikestocode: Machine Learning from Scratch🧠\n",
      "\n",
      "I built an open-source repo with clean Python implementations of ML algorithms.\n",
      "\n",
      "Superv…\n",
      "--------------------------------------------------------------------------------\n",
      "RT @TheSoftLifeNaza: In today’s rapidly evolving digital landscape, the demand for computing power is surging, driven by advancements in ar…\n",
      "--------------------------------------------------------------------------------\n",
      "Investment in AI and machine learning drives Airbnb's innovation. How do you see these technologies shaping the future? #AIInnovation $AIMASTER\n",
      "--------------------------------------------------------------------------------\n",
      "A Day in the Life of a Machine Learning Engineer (at a *small* startup) https://t.co/slPnUwvs5l 来自 @YouTube\n",
      "--------------------------------------------------------------------------------\n",
      "A Day in the Life of a Machine Learning Engineer (at a *small* startup) https://t.co/54NKYqkKNY via @YouTube\n",
      "--------------------------------------------------------------------------------\n",
      "Open jasa Joki Website Laravel, React, Machine Learning , Project Programming, Praktikum C, C++, C#, Java, Python, SQL, Golang, Full Skripsi, Build CV, Essay, Makalah, Laprak dan Jurnal(Nasional/Internasional) #zonauang #effichrono #Zonajajan #jokikuliah #jokiskripsi #jokimurah https://t.co/kqNH1wVoWq\n",
      "--------------------------------------------------------------------------------\n",
      "Error fetching tweets for 'Data Science': 429 Too Many Requests\n",
      "Too Many Requests\n"
     ]
    }
   ],
   "source": [
    "import tweepy\n",
    "\n",
    "# Replace with your actual credentials from Twitter Developer Portal\n",
    "BEARER_TOKEN = \"AAAAAAAAAAAAAAAAAAAAAGBV0AEAAAAAeXzIXP0NpI3FHy%2F87eLJzeE3F9U%3Dm8DdgsjGcCKWlwzEoT3lpyv54W3pgmfAEAUFpLRuBJHoqWmpeH\"\n",
    "\n",
    "# Initialize the Twitter Client\n",
    "client = tweepy.Client(bearer_token=BEARER_TOKEN)\n",
    "\n",
    "# List of search queries\n",
    "queries = [\"Python\", \"Machine Learning\", \"Data Science\"]\n",
    "\n",
    "# Fetch recent tweets\n",
    "for query in queries:\n",
    "    try:\n",
    "        response = client.search_recent_tweets(query=query, max_results=10)  # Must be between 10-100\n",
    "        if response.data:\n",
    "            print(f\"Tweets for '{query}':\")\n",
    "            for tweet in response.data:\n",
    "                print(tweet.text)\n",
    "                print(\"-\" * 80)\n",
    "        else:\n",
    "            print(f\"No recent tweets found for '{query}'.\")\n",
    "    except tweepy.TweepyException as e:\n",
    "        print(f\"Error fetching tweets for '{query}': {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "import tweepy\n",
    "\n",
    "BEARER_TOKEN = \"AAAAAAAAAAAAAAAAAAAAAGBV0AEAAAAAeXzIXP0NpI3FHy%2F87eLJzeE3F9U%3Dm8DdgsjGcCKWlwzEoT3lpyv54W3pgmfAEAUFpLRuBJHoqWmpeH\"  # Replace with your actual token\n",
    "\n",
    "client = tweepy.Client(bearer_token=BEARER_TOKEN)\n",
    "\n",
    "try:\n",
    "    response = client.get_user(username=\"TwitterDev\")  # Test with a known account\n",
    "    print(response.data)\n",
    "except tweepy.TweepyException as e:\n",
    "    print(f\"Authentication failed: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User not found or private.\n"
     ]
    }
   ],
   "source": [
    "import tweepy\n",
    "\n",
    "BEARER_TOKEN = \"AAAAAAAAAAAAAAAAAAAAAGBV0AEAAAAAeXzIXP0NpI3FHy%2F87eLJzeE3F9U%3Dm8DdgsjGcCKWlwzEoT3lpyv54W3pgmfAEAUFpLRuBJHoqWmpeH\"  # Ensure it's correct\n",
    "\n",
    "client = tweepy.Client(bearer_token=BEARER_TOKEN)\n",
    "\n",
    "try:\n",
    "    user = client.get_user(username=\"TwitterDev\", user_fields=[\"id\", \"name\", \"username\"])\n",
    "    if user.data:\n",
    "        print(user.data)\n",
    "    else:\n",
    "        print(\"User not found or private.\")\n",
    "except tweepy.TweepyException as e:\n",
    "    print(f\"Authentication failed: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweet ID: 1903344966396715187\n",
      "Author ID: 116378023\n",
      "Created At: 2025-03-22 07:16:17+00:00\n",
      "Tweet: 今日はPythonでキャッチゲームを作ってみました！\n",
      "「創る」が教えてくれる人生の豊かさ｜北斗のけんちゃん #note https://t.co/eOkX1P9SK5 https://t.co/myISaji03V\n",
      "--------------------------------------------------------------------------------\n",
      "Tweet ID: 1903344941666836692\n",
      "Author ID: 169904826\n",
      "Created At: 2025-03-22 07:16:11+00:00\n",
      "Tweet: @elricmann If you think that tech merit plays the fundamental role in popularity you're in for some serious disappointment.\n",
      "\n",
      "It's not totally irrelevant of course, but the lion share for popularity is just random. What is popular becomes more popular.\n",
      "\n",
      "Python simply \"won the lottery\" of AI.\n",
      "--------------------------------------------------------------------------------\n",
      "Tweet ID: 1903344859101925561\n",
      "Author ID: 1681990614840233987\n",
      "Created At: 2025-03-22 07:15:51+00:00\n",
      "Tweet: @gina_millionz It's kinda using computer code (python)\n",
      "\n",
      "To make animation \n",
      "\n",
      "And ston fi is a Dex on Ton Blockchain\n",
      "--------------------------------------------------------------------------------\n",
      "Tweet ID: 1903344791363965120\n",
      "Author ID: 1896823525060550656\n",
      "Created At: 2025-03-22 07:15:35+00:00\n",
      "Tweet: 🚀 Bootcamps are a fast track to data science!\n",
      "👉Comprehensive curriculum (Python, ML)\n",
      "👉Hands-on projects, mentorship &amp; career guidance\n",
      "Top picks: Springboard, Flatiron, General Assembly, Refonte Learning.\n",
      "Start here: https://t.co/8jVPSQMtiz\n",
      "#DataScience #Bootcamps #CareerSwitch https://t.co/hBN5cXighr\n",
      "--------------------------------------------------------------------------------\n",
      "Tweet ID: 1903344657364353114\n",
      "Author ID: 1900654473196040192\n",
      "Created At: 2025-03-22 07:15:03+00:00\n",
      "Tweet: 🔥 Big News!\n",
      "\n",
      "#ElonMusk officially introduces the X Token.🎉\n",
      "\n",
      "➞ 𝗽𝗶𝗻 𝗽𝗼𝘀𝘁 https://t.co/Xam9T52TZw\n",
      "\n",
      " @f_montero_89ins\n",
      "--------------------------------------------------------------------------------\n",
      "Tweet ID: 1903344651643347099\n",
      "Author ID: 1891044786225795072\n",
      "Created At: 2025-03-22 07:15:02+00:00\n",
      "Tweet: fenalaşıp halletsek BOMBANıN kurtaracağını PYTHON ☎ #test ✈ ☺️ kilometre https://t.co/pzH45N4q3w\n",
      "--------------------------------------------------------------------------------\n",
      "Tweet ID: 1903344488115847204\n",
      "Author ID: 352410832\n",
      "Created At: 2025-03-22 07:14:23+00:00\n",
      "Tweet: @Danjsalt Yep the liberal elite are the black knight in Monty Python🤨 https://t.co/QT8VpaV66d\n",
      "--------------------------------------------------------------------------------\n",
      "Tweet ID: 1903344476669563002\n",
      "Author ID: 1877683550709014528\n",
      "Created At: 2025-03-22 07:14:20+00:00\n",
      "Tweet: @webdesignerng @CharlesChu4891 Na em go swallow python\n",
      "--------------------------------------------------------------------------------\n",
      "Tweet ID: 1903344109881860468\n",
      "Author ID: 1864218041942417408\n",
      "Created At: 2025-03-22 07:12:52+00:00\n",
      "Tweet: @Python_Dv I just learned about this - the .split() function splits a variable into a list. Each whitespace, tab, or new line is excluded by the split function, and each word is saved to a different index. [::-1] reverses the order of that list, so I believe the answer is A.\n",
      "--------------------------------------------------------------------------------\n",
      "Tweet ID: 1903344048150286494\n",
      "Author ID: 1352577733256228865\n",
      "Created At: 2025-03-22 07:12:38+00:00\n",
      "Tweet: พนจะได้ดูอ้วลเต้น python แย้วอะ ช้านจะเสียก่อนมั้ย ทุกวันนี้เพลงรันมาคือเขินจนหน้าเบี้ยวจากคนที่ไม่เคยฟังเพลงนี้เลยทุกวันนี้คือฟังทุกวัน คิดถึงอ้วลลลล\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import tweepy\n",
    "\n",
    "# Replace with your actual Bearer Token\n",
    "BEARER_TOKEN = \"AAAAAAAAAAAAAAAAAAAAAGBV0AEAAAAAFXB6uYQbt%2BGDqcRc3gXhf1F1ivQ%3DZ4X3OBJ2SO775CC6d5TUmbcal9f6TW5Hu9sGYEKznbI8MXFvf3\"\n",
    "\n",
    "# Initialize Tweepy client\n",
    "client = tweepy.Client(bearer_token=BEARER_TOKEN)\n",
    "\n",
    "# Define the search query\n",
    "query = \"Python -is:retweet\"  # Excludes retweets\n",
    "\n",
    "try:\n",
    "    # Fetch recent tweets\n",
    "    response = client.search_recent_tweets(query=query, max_results=10, tweet_fields=[\"created_at\", \"author_id\"])\n",
    "\n",
    "    # Check if tweets are retrieved\n",
    "    if response.data:\n",
    "        for tweet in response.data:\n",
    "            print(f\"Tweet ID: {tweet.id}\")\n",
    "            print(f\"Author ID: {tweet.author_id}\")\n",
    "            print(f\"Created At: {tweet.created_at}\")\n",
    "            print(f\"Tweet: {tweet.text}\")\n",
    "            print(\"-\" * 80)\n",
    "    else:\n",
    "        print(\"No tweets found for the given query.\")\n",
    "except tweepy.TweepyException as e:\n",
    "    print(f\"Error: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Waiting for 15 minutes...\n"
     ]
    }
   ],
   "source": [
    "import tweepy\n",
    "import pandas as pd\n",
    "import json\n",
    "import time\n",
    "\n",
    "# Replace with your actual credentials\n",
    "BEARER_TOKEN = \"AAAAAAAAAAAAAAAAAAAAAGBV0AEAAAAAFXB6uYQbt%2BGDqcRc3gXhf1F1ivQ%3DZ4X3OBJ2SO775CC6d5TUmbcal9f6TW5Hu9sGYEKznbI8MXFvf3\"\n",
    "\n",
    "client = tweepy.Client(bearer_token=BEARER_TOKEN)\n",
    "\n",
    "query = \"Python -is:retweet lang:en\"\n",
    "\n",
    "def fetch_tweets():\n",
    "    while True:\n",
    "        try:\n",
    "            tweets = client.search_recent_tweets(\n",
    "                query=query, tweet_fields=[\"id\", \"text\", \"created_at\", \"author_id\"], max_results=5\n",
    "            )\n",
    "            return tweets\n",
    "        except tweepy.TooManyRequests:\n",
    "            print(\"Rate limit exceeded. Waiting for 15 minutes...\")\n",
    "            time.sleep(900)  # Wait for 15 minutes before retrying\n",
    "\n",
    "tweets = fetch_tweets()\n",
    "\n",
    "if tweets and tweets.data:\n",
    "    tweet_list = [{\n",
    "        \"Tweet ID\": tweet.id,\n",
    "        \"Author ID\": tweet.author_id,\n",
    "        \"Created At\": tweet.created_at.strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "        \"Tweet\": tweet.text\n",
    "    } for tweet in tweets.data]\n",
    "\n",
    "    df = pd.DataFrame(tweet_list)\n",
    "    df.to_csv(\"tweets.csv\", index=False, encoding=\"utf-8\")\n",
    "\n",
    "    with open(\"tweets.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(tweet_list, f, indent=4)\n",
    "\n",
    "    print(\"Tweets saved successfully!\")\n",
    "else:\n",
    "    print(\"No tweets found.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
